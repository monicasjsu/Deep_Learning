{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_using_GRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dXE1BrVzBgQFyctGn1NfJiFFHkVob_Zs",
      "authorship_tag": "ABX9TyOqCAVPpiaLOiplpdqGNIDX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monicasjsu/deep_learning/blob/master/Seq2Seq_using_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jji50mG1erC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR_Sc7RbfG03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_file = data = '/content/drive/My Drive/spa-eng/spa.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSu6xTA_fI45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "  \n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "  w = w.strip()\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUUjliFFfKzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dd6754fd-c136-49b3-bbb7-48d0c6c56f62"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrZsLYGXfMfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove the accents, Clean the sentences and Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdsUCOpZfOIo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1c6c7b4f-2422-4e40-8d81-13c4d14531ff"
      },
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwwewmRTfPqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a7NOYxjfRMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4nccLaNf9fQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWXnJla2f_S4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3765fc8b-ee78-493f-d32e-e0631f08e2b9"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMo5cymqgBMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nyFDFvngC9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "928dc95a-f81a-47f9-9262-bbad532c57f2"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "18 ----> lo\n",
            "3737 ----> permitire\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "4 ----> i\n",
            "38 ----> ll\n",
            "1043 ----> allow\n",
            "10 ----> it\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8VkLpRtgGmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thitQCJBgIfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44302892-a385-4506-dc49-8470f5e208f9"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAD2U2RygLxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7DLNmmxgOVV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7241a0fd-a3cd-429c-a201-1f93de632a7b"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKLyfXhzgQRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X1lpGQtgT-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "914e28d5-fe39-46d0-d075-0838b9ba1b58"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak-X-p8lgWFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "    x = self.embedding(x)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "    output, state = self.gru(x)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn4_kygkgYkS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30178f1d-d99d-4cc9-b2e6-2b1c10b771f2"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uIA_de2gapO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsbGL_9ggcyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9UOi2u8gfZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTiEf3Tvghx-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79da6d40-944f-4657-81b1-620e4d65987e"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.4932\n",
            "Epoch 1 Batch 100 Loss 2.1768\n",
            "Epoch 1 Batch 200 Loss 1.8503\n",
            "Epoch 1 Batch 300 Loss 1.7297\n",
            "Epoch 1 Loss 2.0461\n",
            "Time taken for 1 epoch 45.6558096408844 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.5552\n",
            "Epoch 2 Batch 100 Loss 1.4070\n",
            "Epoch 2 Batch 200 Loss 1.4396\n",
            "Epoch 2 Batch 300 Loss 1.2016\n",
            "Epoch 2 Loss 1.3952\n",
            "Time taken for 1 epoch 34.664554834365845 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0539\n",
            "Epoch 3 Batch 100 Loss 0.9394\n",
            "Epoch 3 Batch 200 Loss 1.0113\n",
            "Epoch 3 Batch 300 Loss 0.8491\n",
            "Epoch 3 Loss 0.9871\n",
            "Time taken for 1 epoch 33.9217631816864 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6462\n",
            "Epoch 4 Batch 100 Loss 0.5910\n",
            "Epoch 4 Batch 200 Loss 0.6709\n",
            "Epoch 4 Batch 300 Loss 0.6170\n",
            "Epoch 4 Loss 0.6749\n",
            "Time taken for 1 epoch 34.58425688743591 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.5086\n",
            "Epoch 5 Batch 100 Loss 0.4758\n",
            "Epoch 5 Batch 200 Loss 0.4826\n",
            "Epoch 5 Batch 300 Loss 0.4981\n",
            "Epoch 5 Loss 0.4634\n",
            "Time taken for 1 epoch 34.00940799713135 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2996\n",
            "Epoch 6 Batch 100 Loss 0.3701\n",
            "Epoch 6 Batch 200 Loss 0.3610\n",
            "Epoch 6 Batch 300 Loss 0.3540\n",
            "Epoch 6 Loss 0.3216\n",
            "Time taken for 1 epoch 34.47518301010132 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2173\n",
            "Epoch 7 Batch 100 Loss 0.2405\n",
            "Epoch 7 Batch 200 Loss 0.2018\n",
            "Epoch 7 Batch 300 Loss 0.2643\n",
            "Epoch 7 Loss 0.2284\n",
            "Time taken for 1 epoch 34.01501512527466 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1416\n",
            "Epoch 8 Batch 100 Loss 0.1628\n",
            "Epoch 8 Batch 200 Loss 0.1113\n",
            "Epoch 8 Batch 300 Loss 0.2026\n",
            "Epoch 8 Loss 0.1687\n",
            "Time taken for 1 epoch 34.52036476135254 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1026\n",
            "Epoch 9 Batch 100 Loss 0.1077\n",
            "Epoch 9 Batch 200 Loss 0.1257\n",
            "Epoch 9 Batch 300 Loss 0.0926\n",
            "Epoch 9 Loss 0.1310\n",
            "Time taken for 1 epoch 33.78883504867554 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0886\n",
            "Epoch 10 Batch 100 Loss 0.1060\n",
            "Epoch 10 Batch 200 Loss 0.0917\n",
            "Epoch 10 Batch 300 Loss 0.1329\n",
            "Epoch 10 Loss 0.1067\n",
            "Time taken for 1 epoch 34.2682318687439 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFq51uA6gkYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9fVS-fwgnVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBugmXKtgpp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jelzc41gtYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26e029a1-6c92-44af-c2d3-a3557f148a45"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0a41764a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPkHaAQdgwAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "863e4b4b-75dd-40c1-997e-b88f87fa7ed7"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s too cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrNbLq2CgyV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "20544e46-2414-4d3c-f1ba-85767f62baf7"
      },
      "source": [
        "translate(u'esta es mi vida.')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}