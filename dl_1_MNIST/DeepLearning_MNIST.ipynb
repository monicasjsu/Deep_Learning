{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9QUADF7vD0e",
        "colab_type": "text"
      },
      "source": [
        "**1. Import the MNIST dataset from keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua3tTFhYHKPC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekc-e-afvBaM",
        "colab_type": "code",
        "outputId": "fc5ea20b-9844-43e7-c6c8-4cbf421120ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Download the MNIST dataset from keras\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Make sure images are loaded by plotting at least 1 digit.\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9YyJHOCvMc4",
        "colab_type": "text"
      },
      "source": [
        "**2. one hot encode the output variable. Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pPyrzGIyvrCb",
        "colab": {}
      },
      "source": [
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVMjsXmOwNi_",
        "colab_type": "text"
      },
      "source": [
        "**3. Normalize the values in each pixel to have the value of each pixel in the range of 0 to 1.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udyHtwTPvs4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Reshape the dataset into 3 dimension, with lenght, width and channels to 1 (RGB)\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yY-wyHOwgf_",
        "colab_type": "text"
      },
      "source": [
        "**4. Augment dataset to include additional dataset by artificially altering the training data slightly, like scaling in and out etc. Training on this dataset helps avoid over fitting. Lets use Keras for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw2XoIWcvSxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(zoom_range=0.5, width_shift_range=0.05, height_shift_range=0.05)\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz454Se4wta8",
        "colab_type": "text"
      },
      "source": [
        "**5. Lets define Dense Layer with forward propagation and backward propagation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CEmgnYjvzz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Layer:\n",
        "    def __init__(self, in_neurons, out_neurons, dropout=0.2, learning_rate=0.1):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.random.randn(in_neurons, out_neurons) * 0.01\n",
        "        self.biases = np.zeros(out_neurons)\n",
        "\n",
        "    def forward_propagation(self, input_activations):\n",
        "        activations = np.matmul(input_activations, self.weights) + self.biases\n",
        "        return activations\n",
        "\n",
        "    def backward_propagation(self, input_activations, grad_output):\n",
        "        grad_input = np.dot(grad_output, np.transpose(self.weights))\n",
        "\n",
        "        # Gradient with Weights\n",
        "        grad_weights = np.transpose(np.dot(np.transpose(grad_output), input_activations))\n",
        "        # Gradient with Biases\n",
        "        grad_biases = np.sum(grad_output, axis=0)\n",
        "\n",
        "        # Stochastic Gradient Descent.\n",
        "        self.weights = self.weights - self.learning_rate * grad_weights\n",
        "        self.biases = self.biases - self.learning_rate * grad_biases\n",
        "        return grad_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVlkNbwsxEsJ",
        "colab_type": "text"
      },
      "source": [
        "**6. Lets define Relu Layer with forward propagation and backward propagation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S87Vlk3Pv_58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReLu:\n",
        "    @staticmethod\n",
        "    def forward_propagation(input_activations):\n",
        "        return (input_activations > 0) * input_activations\n",
        "\n",
        "    @staticmethod\n",
        "    def backward_propagation(input_activations, grad_output):\n",
        "        return (input_activations > 0) * grad_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IciLSk9zxLKd",
        "colab_type": "text"
      },
      "source": [
        "**7. Lets define Dropout Layer which takes dropout_ratio and makes those neurons activation zero based on the ratio**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blkkG-CfwEwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dropout:\n",
        "    @staticmethod\n",
        "    def generate_dropout_mask(size, dropout_ratio):\n",
        "        zeros_size = int(size * dropout_ratio)\n",
        "        zeros = np.zeros(zeros_size)\n",
        "        ones = np.ones(size - zeros_size)\n",
        "        dropout_mask = np.asarray(zeros.tolist() + ones.tolist())\n",
        "        random.shuffle(dropout_mask)\n",
        "        return dropout_mask\n",
        "\n",
        "    def __init__(self, size, dropout_ratio=0.20):\n",
        "        self.dropout_mask = Dropout.generate_dropout_mask(size, dropout_ratio)\n",
        "\n",
        "    def forward_propagation(self, input_activations):\n",
        "        return np.multiply(input_activations, self.dropout_mask)\n",
        "\n",
        "    def backward_propagation(self, input_activations, grad_output):\n",
        "        return np.multiply(grad_output, self.dropout_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwbkF4ZeyNxU",
        "colab_type": "text"
      },
      "source": [
        "**8. Lets define the neural network with 3 Dense Layes, 2 ReLu layers and 2 Droput layers.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnOCB0IBwJUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neural_network = [\n",
        "    Layer(X_train.shape[1] * X_train.shape[2], 200),\n",
        "    Dropout(200, 0.20),\n",
        "    ReLu(),\n",
        "    Layer(200, 100),\n",
        "    Dropout(100, 0.10),\n",
        "    ReLu(),\n",
        "    Layer(100, 10)\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQVdzom80mSZ",
        "colab_type": "text"
      },
      "source": [
        "**9. Method to calculate the error using softmax function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gzqKOb10b9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax_error(out_activations, y):\n",
        "    softmax = np.exp(out_activations) / np.exp(out_activations).sum(axis=-1, keepdims=True)\n",
        "    return softmax - y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8Wj6W8C0vYi",
        "colab_type": "text"
      },
      "source": [
        "**10. Calculate the weights of all neurons in network using the forward propagation logic corresponging to each layer.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9X38Woq0cMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_activations(X):\n",
        "    # Get the layer activations\n",
        "    X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
        "    activations = []\n",
        "    for level in range(len(neural_network)):\n",
        "        next_activations = neural_network[level].forward_propagation(X)\n",
        "        activations.append(next_activations)\n",
        "        X = next_activations\n",
        "    return activations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY5HFBPZ04zN",
        "colab_type": "text"
      },
      "source": [
        "**11. Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PGDYkYf0cJr",
        "colab_type": "code",
        "outputId": "f22f4e7e-a346-4ff0-da58-b6a40e36c7a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train(X, y):\n",
        "    activations = get_activations(X)\n",
        "    output_activations = activations[-1]\n",
        "\n",
        "    loss = softmax_error(output_activations, y)\n",
        "    for i in range(1, len(neural_network)):\n",
        "        network = neural_network[len(neural_network) - i]\n",
        "        loss = network.backward_propagation(activations[len(neural_network) - i - 1], loss)\n",
        "\n",
        "      \n",
        "def predict(X):\n",
        "    out_activations = get_activations(X)[-1]\n",
        "    return out_activations.argmax(axis=-1)\n",
        "\n",
        "\n",
        "def train_datagen(datagen, total_iterations):\n",
        "  for iteration in range(total_iterations):\n",
        "      total_mini_batch_trainings = 100\n",
        "      for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=8):\n",
        "          train(X_batch.reshape(-1, X_batch.shape[1], X_batch.shape[2]), y_batch)\n",
        "          total_mini_batch_trainings -= 1\n",
        "          if total_mini_batch_trainings == 0:\n",
        "              break\n",
        "      print(\"=====================Iteration: {}=====================\".format(iteration))\n",
        "      train_result = [np.mean(predict(X_train) == y_train.argmax(axis=-1))]\n",
        "      print(\"Train accuracy: {}%\".format(train_result[-1] * 100))\n",
        "      test_result = [np.mean(predict(X_test) == y_test.argmax(axis=-1))]\n",
        "      print(\"Test accuracy: {}%\".format(test_result[-1] * 100))\n",
        "\n",
        "# Training the model with Augumented data generated\n",
        "train_datagen(datagen, 110)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=====================Iteration: 0=====================\n",
            "Train accuracy: 9.863333333333333%\n",
            "Test accuracy: 9.58%\n",
            "=====================Iteration: 1=====================\n",
            "Train accuracy: 16.941666666666666%\n",
            "Test accuracy: 17.18%\n",
            "=====================Iteration: 2=====================\n",
            "Train accuracy: 32.85333333333333%\n",
            "Test accuracy: 33.2%\n",
            "=====================Iteration: 3=====================\n",
            "Train accuracy: 45.535%\n",
            "Test accuracy: 46.46%\n",
            "=====================Iteration: 4=====================\n",
            "Train accuracy: 53.978333333333325%\n",
            "Test accuracy: 55.65%\n",
            "=====================Iteration: 5=====================\n",
            "Train accuracy: 54.49666666666667%\n",
            "Test accuracy: 54.92%\n",
            "=====================Iteration: 6=====================\n",
            "Train accuracy: 59.40833333333333%\n",
            "Test accuracy: 60.23%\n",
            "=====================Iteration: 7=====================\n",
            "Train accuracy: 63.48666666666667%\n",
            "Test accuracy: 64.71000000000001%\n",
            "=====================Iteration: 8=====================\n",
            "Train accuracy: 52.38666666666667%\n",
            "Test accuracy: 53.410000000000004%\n",
            "=====================Iteration: 9=====================\n",
            "Train accuracy: 63.60166666666667%\n",
            "Test accuracy: 65.14%\n",
            "=====================Iteration: 10=====================\n",
            "Train accuracy: 64.865%\n",
            "Test accuracy: 66.60000000000001%\n",
            "=====================Iteration: 11=====================\n",
            "Train accuracy: 65.85833333333333%\n",
            "Test accuracy: 66.39%\n",
            "=====================Iteration: 12=====================\n",
            "Train accuracy: 64.56166666666667%\n",
            "Test accuracy: 65.83%\n",
            "=====================Iteration: 13=====================\n",
            "Train accuracy: 49.656666666666666%\n",
            "Test accuracy: 50.96000000000001%\n",
            "=====================Iteration: 14=====================\n",
            "Train accuracy: 53.300000000000004%\n",
            "Test accuracy: 54.620000000000005%\n",
            "=====================Iteration: 15=====================\n",
            "Train accuracy: 64.07000000000001%\n",
            "Test accuracy: 65.81%\n",
            "=====================Iteration: 16=====================\n",
            "Train accuracy: 64.30666666666667%\n",
            "Test accuracy: 63.839999999999996%\n",
            "=====================Iteration: 17=====================\n",
            "Train accuracy: 76.09666666666666%\n",
            "Test accuracy: 77.53999999999999%\n",
            "=====================Iteration: 18=====================\n",
            "Train accuracy: 72.04166666666667%\n",
            "Test accuracy: 72.24000000000001%\n",
            "=====================Iteration: 19=====================\n",
            "Train accuracy: 60.806666666666665%\n",
            "Test accuracy: 61.0%\n",
            "=====================Iteration: 20=====================\n",
            "Train accuracy: 75.14999999999999%\n",
            "Test accuracy: 76.0%\n",
            "=====================Iteration: 21=====================\n",
            "Train accuracy: 75.38333333333334%\n",
            "Test accuracy: 76.95%\n",
            "=====================Iteration: 22=====================\n",
            "Train accuracy: 75.4%\n",
            "Test accuracy: 77.22%\n",
            "=====================Iteration: 23=====================\n",
            "Train accuracy: 72.58833333333334%\n",
            "Test accuracy: 74.28%\n",
            "=====================Iteration: 24=====================\n",
            "Train accuracy: 71.50333333333333%\n",
            "Test accuracy: 72.33000000000001%\n",
            "=====================Iteration: 25=====================\n",
            "Train accuracy: 73.04666666666667%\n",
            "Test accuracy: 74.79%\n",
            "=====================Iteration: 26=====================\n",
            "Train accuracy: 66.03999999999999%\n",
            "Test accuracy: 67.95%\n",
            "=====================Iteration: 27=====================\n",
            "Train accuracy: 74.50166666666667%\n",
            "Test accuracy: 75.56%\n",
            "=====================Iteration: 28=====================\n",
            "Train accuracy: 77.11666666666666%\n",
            "Test accuracy: 78.68%\n",
            "=====================Iteration: 29=====================\n",
            "Train accuracy: 75.42166666666667%\n",
            "Test accuracy: 77.13%\n",
            "=====================Iteration: 30=====================\n",
            "Train accuracy: 77.65166666666666%\n",
            "Test accuracy: 78.77%\n",
            "=====================Iteration: 31=====================\n",
            "Train accuracy: 63.83333333333333%\n",
            "Test accuracy: 64.47%\n",
            "=====================Iteration: 32=====================\n",
            "Train accuracy: 77.38166666666667%\n",
            "Test accuracy: 78.36999999999999%\n",
            "=====================Iteration: 33=====================\n",
            "Train accuracy: 75.00166666666667%\n",
            "Test accuracy: 75.12%\n",
            "=====================Iteration: 34=====================\n",
            "Train accuracy: 75.48666666666666%\n",
            "Test accuracy: 76.35%\n",
            "=====================Iteration: 35=====================\n",
            "Train accuracy: 77.79833333333333%\n",
            "Test accuracy: 78.81%\n",
            "=====================Iteration: 36=====================\n",
            "Train accuracy: 78.35499999999999%\n",
            "Test accuracy: 79.16%\n",
            "=====================Iteration: 37=====================\n",
            "Train accuracy: 74.28833333333333%\n",
            "Test accuracy: 75.72%\n",
            "=====================Iteration: 38=====================\n",
            "Train accuracy: 77.7%\n",
            "Test accuracy: 78.86%\n",
            "=====================Iteration: 39=====================\n",
            "Train accuracy: 73.36333333333333%\n",
            "Test accuracy: 74.63%\n",
            "=====================Iteration: 40=====================\n",
            "Train accuracy: 79.12833333333333%\n",
            "Test accuracy: 80.44%\n",
            "=====================Iteration: 41=====================\n",
            "Train accuracy: 78.77%\n",
            "Test accuracy: 79.54%\n",
            "=====================Iteration: 42=====================\n",
            "Train accuracy: 77.60166666666667%\n",
            "Test accuracy: 78.66%\n",
            "=====================Iteration: 43=====================\n",
            "Train accuracy: 78.99833333333333%\n",
            "Test accuracy: 80.36999999999999%\n",
            "=====================Iteration: 44=====================\n",
            "Train accuracy: 79.59666666666666%\n",
            "Test accuracy: 80.23%\n",
            "=====================Iteration: 45=====================\n",
            "Train accuracy: 70.00833333333333%\n",
            "Test accuracy: 70.85000000000001%\n",
            "=====================Iteration: 46=====================\n",
            "Train accuracy: 71.66666666666667%\n",
            "Test accuracy: 72.03%\n",
            "=====================Iteration: 47=====================\n",
            "Train accuracy: 78.47166666666666%\n",
            "Test accuracy: 79.11%\n",
            "=====================Iteration: 48=====================\n",
            "Train accuracy: 80.73166666666667%\n",
            "Test accuracy: 81.62%\n",
            "=====================Iteration: 49=====================\n",
            "Train accuracy: 77.36833333333333%\n",
            "Test accuracy: 78.32000000000001%\n",
            "=====================Iteration: 50=====================\n",
            "Train accuracy: 81.07%\n",
            "Test accuracy: 81.74%\n",
            "=====================Iteration: 51=====================\n",
            "Train accuracy: 72.92333333333333%\n",
            "Test accuracy: 74.14%\n",
            "=====================Iteration: 52=====================\n",
            "Train accuracy: 80.37166666666667%\n",
            "Test accuracy: 81.07%\n",
            "=====================Iteration: 53=====================\n",
            "Train accuracy: 78.21166666666667%\n",
            "Test accuracy: 78.82000000000001%\n",
            "=====================Iteration: 54=====================\n",
            "Train accuracy: 79.36333333333333%\n",
            "Test accuracy: 81.27%\n",
            "=====================Iteration: 55=====================\n",
            "Train accuracy: 78.16666666666666%\n",
            "Test accuracy: 79.69000000000001%\n",
            "=====================Iteration: 56=====================\n",
            "Train accuracy: 79.325%\n",
            "Test accuracy: 80.42%\n",
            "=====================Iteration: 57=====================\n",
            "Train accuracy: 82.16%\n",
            "Test accuracy: 82.94%\n",
            "=====================Iteration: 58=====================\n",
            "Train accuracy: 80.42%\n",
            "Test accuracy: 81.53%\n",
            "=====================Iteration: 59=====================\n",
            "Train accuracy: 84.39333333333333%\n",
            "Test accuracy: 85.18%\n",
            "=====================Iteration: 60=====================\n",
            "Train accuracy: 72.57333333333334%\n",
            "Test accuracy: 73.81%\n",
            "=====================Iteration: 61=====================\n",
            "Train accuracy: 81.54333333333334%\n",
            "Test accuracy: 82.66%\n",
            "=====================Iteration: 62=====================\n",
            "Train accuracy: 80.26833333333333%\n",
            "Test accuracy: 81.5%\n",
            "=====================Iteration: 63=====================\n",
            "Train accuracy: 82.77833333333334%\n",
            "Test accuracy: 84.13000000000001%\n",
            "=====================Iteration: 64=====================\n",
            "Train accuracy: 80.435%\n",
            "Test accuracy: 82.11%\n",
            "=====================Iteration: 65=====================\n",
            "Train accuracy: 82.75666666666666%\n",
            "Test accuracy: 83.81%\n",
            "=====================Iteration: 66=====================\n",
            "Train accuracy: 83.32166666666667%\n",
            "Test accuracy: 83.67999999999999%\n",
            "=====================Iteration: 67=====================\n",
            "Train accuracy: 79.49833333333333%\n",
            "Test accuracy: 81.08999999999999%\n",
            "=====================Iteration: 68=====================\n",
            "Train accuracy: 81.765%\n",
            "Test accuracy: 83.3%\n",
            "=====================Iteration: 69=====================\n",
            "Train accuracy: 79.44%\n",
            "Test accuracy: 80.55%\n",
            "=====================Iteration: 70=====================\n",
            "Train accuracy: 80.75833333333333%\n",
            "Test accuracy: 81.49%\n",
            "=====================Iteration: 71=====================\n",
            "Train accuracy: 84.665%\n",
            "Test accuracy: 85.61%\n",
            "=====================Iteration: 72=====================\n",
            "Train accuracy: 78.84333333333333%\n",
            "Test accuracy: 79.91%\n",
            "=====================Iteration: 73=====================\n",
            "Train accuracy: 80.99333333333333%\n",
            "Test accuracy: 82.42%\n",
            "=====================Iteration: 74=====================\n",
            "Train accuracy: 72.81666666666666%\n",
            "Test accuracy: 74.53%\n",
            "=====================Iteration: 75=====================\n",
            "Train accuracy: 79.835%\n",
            "Test accuracy: 81.61%\n",
            "=====================Iteration: 76=====================\n",
            "Train accuracy: 81.39%\n",
            "Test accuracy: 81.53%\n",
            "=====================Iteration: 77=====================\n",
            "Train accuracy: 83.80166666666666%\n",
            "Test accuracy: 84.67%\n",
            "=====================Iteration: 78=====================\n",
            "Train accuracy: 84.63833333333334%\n",
            "Test accuracy: 85.63%\n",
            "=====================Iteration: 79=====================\n",
            "Train accuracy: 77.62833333333333%\n",
            "Test accuracy: 78.97999999999999%\n",
            "=====================Iteration: 80=====================\n",
            "Train accuracy: 79.44833333333334%\n",
            "Test accuracy: 80.35%\n",
            "=====================Iteration: 81=====================\n",
            "Train accuracy: 78.25999999999999%\n",
            "Test accuracy: 78.83%\n",
            "=====================Iteration: 82=====================\n",
            "Train accuracy: 82.205%\n",
            "Test accuracy: 83.44%\n",
            "=====================Iteration: 83=====================\n",
            "Train accuracy: 83.63000000000001%\n",
            "Test accuracy: 84.66%\n",
            "=====================Iteration: 84=====================\n",
            "Train accuracy: 84.49666666666667%\n",
            "Test accuracy: 85.08%\n",
            "=====================Iteration: 85=====================\n",
            "Train accuracy: 77.825%\n",
            "Test accuracy: 78.05%\n",
            "=====================Iteration: 86=====================\n",
            "Train accuracy: 83.43166666666667%\n",
            "Test accuracy: 84.56%\n",
            "=====================Iteration: 87=====================\n",
            "Train accuracy: 77.945%\n",
            "Test accuracy: 78.23%\n",
            "=====================Iteration: 88=====================\n",
            "Train accuracy: 83.88%\n",
            "Test accuracy: 84.95%\n",
            "=====================Iteration: 89=====================\n",
            "Train accuracy: 84.53500000000001%\n",
            "Test accuracy: 85.5%\n",
            "=====================Iteration: 90=====================\n",
            "Train accuracy: 84.38333333333333%\n",
            "Test accuracy: 85.69%\n",
            "=====================Iteration: 91=====================\n",
            "Train accuracy: 85.10166666666666%\n",
            "Test accuracy: 85.77%\n",
            "=====================Iteration: 92=====================\n",
            "Train accuracy: 80.91333333333334%\n",
            "Test accuracy: 82.57%\n",
            "=====================Iteration: 93=====================\n",
            "Train accuracy: 84.80499999999999%\n",
            "Test accuracy: 85.47%\n",
            "=====================Iteration: 94=====================\n",
            "Train accuracy: 76.92833333333333%\n",
            "Test accuracy: 77.77%\n",
            "=====================Iteration: 95=====================\n",
            "Train accuracy: 81.035%\n",
            "Test accuracy: 82.69999999999999%\n",
            "=====================Iteration: 96=====================\n",
            "Train accuracy: 84.90666666666667%\n",
            "Test accuracy: 85.78%\n",
            "=====================Iteration: 97=====================\n",
            "Train accuracy: 85.51333333333334%\n",
            "Test accuracy: 86.48%\n",
            "=====================Iteration: 98=====================\n",
            "Train accuracy: 84.27333333333334%\n",
            "Test accuracy: 85.77%\n",
            "=====================Iteration: 99=====================\n",
            "Train accuracy: 84.96833333333333%\n",
            "Test accuracy: 85.88%\n",
            "=====================Iteration: 100=====================\n",
            "Train accuracy: 80.52166666666668%\n",
            "Test accuracy: 81.44%\n",
            "=====================Iteration: 101=====================\n",
            "Train accuracy: 85.46333333333334%\n",
            "Test accuracy: 86.59%\n",
            "=====================Iteration: 102=====================\n",
            "Train accuracy: 83.05333333333334%\n",
            "Test accuracy: 84.84%\n",
            "=====================Iteration: 103=====================\n",
            "Train accuracy: 84.31833333333333%\n",
            "Test accuracy: 85.49%\n",
            "=====================Iteration: 104=====================\n",
            "Train accuracy: 86.12166666666667%\n",
            "Test accuracy: 86.85000000000001%\n",
            "=====================Iteration: 105=====================\n",
            "Train accuracy: 82.84833333333333%\n",
            "Test accuracy: 83.7%\n",
            "=====================Iteration: 106=====================\n",
            "Train accuracy: 83.66%\n",
            "Test accuracy: 84.65%\n",
            "=====================Iteration: 107=====================\n",
            "Train accuracy: 84.495%\n",
            "Test accuracy: 85.91%\n",
            "=====================Iteration: 108=====================\n",
            "Train accuracy: 77.72833333333334%\n",
            "Test accuracy: 78.56%\n",
            "=====================Iteration: 109=====================\n",
            "Train accuracy: 82.58666666666666%\n",
            "Test accuracy: 83.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2w4IYXfAFjl",
        "colab_type": "code",
        "outputId": "b2957d8e-ca2c-444d-8d78-9f38ce1a5892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training the model without skewing the digits\n",
        "datagen_plain = ImageDataGenerator(zoom_range=0, width_shift_range=0, height_shift_range=0)\n",
        "train_datagen(datagen_plain, 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=====================Iteration: 0=====================\n",
            "Train accuracy: 92.59166666666667%\n",
            "Test accuracy: 92.73%\n",
            "=====================Iteration: 1=====================\n",
            "Train accuracy: 93.45%\n",
            "Test accuracy: 93.27%\n",
            "=====================Iteration: 2=====================\n",
            "Train accuracy: 91.64333333333333%\n",
            "Test accuracy: 91.75999999999999%\n",
            "=====================Iteration: 3=====================\n",
            "Train accuracy: 93.05499999999999%\n",
            "Test accuracy: 93.41000000000001%\n",
            "=====================Iteration: 4=====================\n",
            "Train accuracy: 93.26333333333334%\n",
            "Test accuracy: 93.56%\n",
            "=====================Iteration: 5=====================\n",
            "Train accuracy: 90.95333333333333%\n",
            "Test accuracy: 91.06%\n",
            "=====================Iteration: 6=====================\n",
            "Train accuracy: 92.93166666666667%\n",
            "Test accuracy: 92.74%\n",
            "=====================Iteration: 7=====================\n",
            "Train accuracy: 92.43333333333334%\n",
            "Test accuracy: 92.42%\n",
            "=====================Iteration: 8=====================\n",
            "Train accuracy: 92.48666666666666%\n",
            "Test accuracy: 92.42%\n",
            "=====================Iteration: 9=====================\n",
            "Train accuracy: 93.34666666666666%\n",
            "Test accuracy: 93.39%\n",
            "=====================Iteration: 10=====================\n",
            "Train accuracy: 92.14666666666666%\n",
            "Test accuracy: 92.31%\n",
            "=====================Iteration: 11=====================\n",
            "Train accuracy: 89.44666666666666%\n",
            "Test accuracy: 89.55%\n",
            "=====================Iteration: 12=====================\n",
            "Train accuracy: 92.83%\n",
            "Test accuracy: 92.84%\n",
            "=====================Iteration: 13=====================\n",
            "Train accuracy: 93.475%\n",
            "Test accuracy: 93.47999999999999%\n",
            "=====================Iteration: 14=====================\n",
            "Train accuracy: 92.38333333333333%\n",
            "Test accuracy: 91.85%\n",
            "=====================Iteration: 15=====================\n",
            "Train accuracy: 92.23166666666667%\n",
            "Test accuracy: 92.36%\n",
            "=====================Iteration: 16=====================\n",
            "Train accuracy: 92.60166666666667%\n",
            "Test accuracy: 92.84%\n",
            "=====================Iteration: 17=====================\n",
            "Train accuracy: 92.04833333333333%\n",
            "Test accuracy: 92.36999999999999%\n",
            "=====================Iteration: 18=====================\n",
            "Train accuracy: 92.5%\n",
            "Test accuracy: 92.51%\n",
            "=====================Iteration: 19=====================\n",
            "Train accuracy: 92.45666666666666%\n",
            "Test accuracy: 92.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pumEXYsj7bLa",
        "colab_type": "text"
      },
      "source": [
        "**12. Test results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QcGkRIx0cHE",
        "colab_type": "code",
        "outputId": "aec700dd-8747-43dc-9204-a2ca5d779740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = predict(X_test)\n",
        "print('confusion matrix for the real test set:\\n', confusion_matrix(y_test.argmax(axis=-1), y_pred))\n",
        "final_test_accuracy = np.mean(predict(X_test) == y_test.argmax(axis=-1)) * 100\n",
        "print(\"Final Test Accuracy: {}%\".format(final_test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix for the real test set:\n",
            " [[ 957    0    4    1    0   12    2    0    2    2]\n",
            " [   0 1112    7    5    2    1    3    0    3    2]\n",
            " [  13    2  946   33    9    4    2    7   13    3]\n",
            " [   0    0    8  967    0   18    0    3    6    8]\n",
            " [   4    1    2    0  945    2    6    0    1   21]\n",
            " [   2    0    3   23    6  843    2    1    7    5]\n",
            " [  20    4    6    2   15   31  871    0    8    1]\n",
            " [   2   12   15   16   23    6    0  879    0   75]\n",
            " [   3    0   13   49   12   38    3    1  839   16]\n",
            " [   4    3    2   11   60    6    0    2    2  919]]\n",
            "Final Test Accuracy: 92.78%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}