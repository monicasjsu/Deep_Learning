{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_tabular_wine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QiByFrrotIf1OMkcXjIlluLZBA_LyJQQ",
      "authorship_tag": "ABX9TyOjXgXiEUWhgeddsTMc23OD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monicasjsu/deep_learning/blob/master/1_tabular_wine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB60zL0MpzWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "torch.set_printoptions(edgeitems=2, precision=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGlvCV_bp5HR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "28adb9ed-202a-42ab-a3ee-de5fdac3505a"
      },
      "source": [
        "import csv\n",
        "wine_path = \"drive/My Drive/Datasets/winequality-white.csv\"\n",
        "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\", skiprows=1)\n",
        "wineq_numpy"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
              "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
              "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
              "       ...,\n",
              "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
              "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
              "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtUOHcQX6VKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e7929b3e-b97a-45bd-cf43-30e0b5fdb778"
      },
      "source": [
        "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
        "wineq_numpy.shape, col_list"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4898, 12),\n",
              " ['fixed acidity',\n",
              "  'volatile acidity',\n",
              "  'citric acid',\n",
              "  'residual sugar',\n",
              "  'chlorides',\n",
              "  'free sulfur dioxide',\n",
              "  'total sulfur dioxide',\n",
              "  'density',\n",
              "  'pH',\n",
              "  'sulphates',\n",
              "  'alcohol',\n",
              "  'quality'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v26KVuuG6Y79",
        "colab_type": "text"
      },
      "source": [
        "Converting the NumPy array to a PyTorch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGl7E39U6bU8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cf0e1af-9626-43b7-ae12-99a76a470680"
      },
      "source": [
        "wineq = torch.from_numpy(wineq_numpy)\n",
        "wineq.shape, wineq.type()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898, 12]), 'torch.FloatTensor')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr3xmiKi6jFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2773b744-8c57-408b-bb7b-939ae25f38ab"
      },
      "source": [
        "data = wineq[:, :-1]\n",
        "data, data.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7.00,  0.27,  ...,  0.45,  8.80],\n",
              "         [ 6.30,  0.30,  ...,  0.49,  9.50],\n",
              "         ...,\n",
              "         [ 5.50,  0.29,  ...,  0.38, 12.80],\n",
              "         [ 6.00,  0.21,  ...,  0.32, 11.80]]), torch.Size([4898, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB6oT-ZI6luw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9688ddd4-d3dc-466d-e01f-e4bc42292a6f"
      },
      "source": [
        "target = wineq[:, -1]\n",
        "target, target.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6., 6.,  ..., 7., 6.]), torch.Size([4898]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_ZqjYE26oKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c937fd36-5b0e-48fe-daba-ed0442c840e1"
      },
      "source": [
        "target = wineq[:, -1].long()\n",
        "target"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 6,  ..., 7, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzdgNSdP66HI",
        "colab_type": "text"
      },
      "source": [
        "Using one-hot encoding by using the scatter_ method, which fills the tensor with values from a source tensor along the indices provided as arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxSKggZx605F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "93855015-6696-498c-c912-6eeb105e130c"
      },
      "source": [
        "target_onehot = torch.zeros(target.shape[0], 10)\n",
        "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.,  ..., 0., 0.],\n",
              "        [0., 0.,  ..., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0.,  ..., 0., 0.],\n",
              "        [0., 0.,  ..., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvMdYGKu7Jx5",
        "colab_type": "text"
      },
      "source": [
        "Adding extra dummy dimension to target by using unsqueeze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YgkV5pE7CXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "931bf81c-ba5d-47fb-f89b-dfcf5380f8b5"
      },
      "source": [
        "target_unsqueezed = target.unsqueeze(1)\n",
        "target_unsqueezed"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6],\n",
              "        [6],\n",
              "        ...,\n",
              "        [7],\n",
              "        [6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47KZs85Z7Tnf",
        "colab_type": "text"
      },
      "source": [
        "Checking the mean for each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klKWHLaq7P4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a9839306-c7ff-4696-9382-243073190e44"
      },
      "source": [
        "data_mean = torch.mean(data, dim=0)\n",
        "data_mean"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.85e+00, 2.78e-01, 3.34e-01, 6.39e+00, 4.58e-02, 3.53e+01, 1.38e+02,\n",
              "        9.94e-01, 3.19e+00, 4.90e-01, 1.05e+01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLbRXIEj7ZAn",
        "colab_type": "text"
      },
      "source": [
        "Checking the variance of each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvzgcKs97YIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b9fb8ed4-c1fa-45a0-d86b-c1f9d8aa5914"
      },
      "source": [
        "data_var = torch.var(data, dim=0)\n",
        "data_var"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7.12e-01, 1.02e-02, 1.46e-02, 2.57e+01, 4.77e-04, 2.89e+02, 1.81e+03,\n",
              "        8.95e-06, 2.28e-02, 1.30e-02, 1.51e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMIU8z6t7gum",
        "colab_type": "text"
      },
      "source": [
        "Normalizing the data by subtracting the mean and dividing by the standard deviation, which helps with the learning process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ZPw2oH7fwk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4a6d0844-0e64-4499-fcee-c9f38a7ed253"
      },
      "source": [
        "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
        "data_normalized"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.72e-01, -8.18e-02,  ..., -3.49e-01, -1.39e+00],\n",
              "        [-6.57e-01,  2.16e-01,  ...,  1.35e-03, -8.24e-01],\n",
              "        ...,\n",
              "        [-1.61e+00,  1.17e-01,  ..., -9.63e-01,  1.86e+00],\n",
              "        [-1.01e+00, -6.77e-01,  ..., -1.49e+00,  1.04e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP5nsvWM7uiO",
        "colab_type": "text"
      },
      "source": [
        "Using the torch.le function to determine which rows in target correspond to a score less than or equal to 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8E0Q2V77sXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a75732e-f30e-47bd-b8db-5f96393915c1"
      },
      "source": [
        "bad_indexes = torch.le(target, 3)\n",
        "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(20))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26Khv5Mn7z_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac3bb293-de04-402f-e271-cbf1372689e9"
      },
      "source": [
        "bad_data = data[bad_indexes]\n",
        "bad_data.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0o0jxb_76of",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "180b3bd8-eb8b-49ef-fd8c-0b90404dd88f"
      },
      "source": [
        "torch.Size([20, 11])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn4qebne8Mcv",
        "colab_type": "text"
      },
      "source": [
        "Starting to get information about wines grouped into good, middling,\n",
        "and bad categories. Take the .mean() of each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1eacE-k8Gmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e3df7a76-c962-4385-f66e-7e5afc0011c4"
      },
      "source": [
        "bad_data = data[torch.le(target, 3)]\n",
        "mid_data = data[torch.gt(target, 3) & torch.lt(target, 7)]\n",
        "good_data = data[torch.ge(target, 7)]\n",
        "bad_mean = torch.mean(bad_data, dim=0)\n",
        "mid_mean = torch.mean(mid_data, dim=0)\n",
        "good_mean = torch.mean(good_data, dim=0)\n",
        "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
        " print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 0 fixed acidity          7.60   6.89   6.73\n",
            " 1 volatile acidity       0.33   0.28   0.27\n",
            " 2 citric acid            0.34   0.34   0.33\n",
            " 3 residual sugar         6.39   6.71   5.26\n",
            " 4 chlorides              0.05   0.05   0.04\n",
            " 5 free sulfur dioxide   53.33  35.42  34.55\n",
            " 6 total sulfur dioxide 170.60 141.83 125.25\n",
            " 7 density                0.99   0.99   0.99\n",
            " 8 pH                     3.19   3.18   3.22\n",
            " 9 sulphates              0.47   0.49   0.50\n",
            "10 alcohol               10.34  10.26  11.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zNHhS5K8Xpj",
        "colab_type": "text"
      },
      "source": [
        "Trying to get the indexes in which the total sulfur dioxide column is below the midpoint you calculated earlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDP-ZwWq8SSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1db402dc-360b-4270-800d-11283ae02287"
      },
      "source": [
        "total_sulfur_threshold = 141.83\n",
        "total_sulfur_data = data[:,6]\n",
        "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
        "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(2727))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYQIr6c78lvH",
        "colab_type": "text"
      },
      "source": [
        "Trying to get the indexes of the good wines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7tUVGVK8cu8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "555af65a-1c04-43be-e916-0793d5efe6a7"
      },
      "source": [
        "actual_indexes = torch.gt(target, 5)\n",
        "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(3258))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr6u7j2T84du",
        "colab_type": "text"
      },
      "source": [
        "Trying to see how well our predictions line up with the actual rankings.\n",
        "Performing a logical and between our prediction indexes and the good indexes and use that intersection of\n",
        "wines in agreement to determine how well it did:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU8EsuLV8qSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95e34042-fb80-430a-a078-7cc7a1b44b72"
      },
      "source": [
        "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
        "n_predicted = torch.sum(predicted_indexes).item()\n",
        "n_actual = torch.sum(actual_indexes).item()\n",
        "n_matches, n_matches / n_predicted, n_matches / n_actual"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2018, 0.74000733406674, 0.6193984039287906)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}