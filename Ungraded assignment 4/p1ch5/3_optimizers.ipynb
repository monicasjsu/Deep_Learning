{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_optimizers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNhhYHG9QFmaufUoG+colc8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monicasjsu/deep_learning/blob/master/3_optimizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKhKRQLmtmci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CahDclWhtq56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "feadab24-ae95-4bb8-c53f-aec489950046"
      },
      "source": [
        "dir(optim)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ASGD',\n",
              " 'Adadelta',\n",
              " 'Adagrad',\n",
              " 'Adam',\n",
              " 'AdamW',\n",
              " 'Adamax',\n",
              " 'LBFGS',\n",
              " 'Optimizer',\n",
              " 'RMSprop',\n",
              " 'Rprop',\n",
              " 'SGD',\n",
              " 'SparseAdam',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " 'lr_scheduler']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8IENkZXt93x",
        "colab_type": "text"
      },
      "source": [
        "Create params and instantiate a gradient descent optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sprB305t0JX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.SGD([params], lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1kzHn-ruSGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t_c = torch.tensor([1.0, 3.0, 7.0])\n",
        "# t_u = torch.tensor([35.7, 55.9, 58.2])\n",
        "# t_un = 0.1 * t_u\n",
        "\n",
        "\n",
        "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0])\n",
        "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4])\n",
        "t_un = 0.1 * t_u"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QVlXQpyuUwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(t_u, w, b):\n",
        " return w * t_u + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK9joURsuWyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(t_p, t_c):\n",
        " squared_diffs = (t_p - t_c)**2\n",
        " return squared_diffs.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiR8CxKUuBER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ad4722c-4041-4306-c6f7-c04728c6b292"
      },
      "source": [
        "t_p = model(t_u, *params)\n",
        "loss = loss_fn(t_p, t_c)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "params"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.5483e-01, -8.2600e-04], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq1_Vl3suh7V",
        "colab_type": "text"
      },
      "source": [
        "Loop-ready code, with the extra zero_grad in the right spot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJYs5FQ6ucPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ae40905-b707-470e-b2ed-8d4570f9b4cf"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "t_p = model(t_un, *params)\n",
        "loss = loss_fn(t_p, t_c)\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "params"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.7761, 0.1064], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOR5h-rqu5qX",
        "colab_type": "text"
      },
      "source": [
        "Updating the training loop by providing the list of params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7D9_luHumkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
        " for epoch in range(1, n_epochs + 1):\n",
        "  t_p = model(t_u, *params)\n",
        "  loss = loss_fn(t_p, t_c)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 500 == 0:\n",
        "   print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        " return params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wpk-PSRvBgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8e217345-c7f0-48b2-9bfb-20009eb5359a"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "training_loop(\n",
        " n_epochs = 5000,\n",
        " optimizer = optimizer,\n",
        " params = params,\n",
        " t_u = t_un,\n",
        " t_c = t_c)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 500, Loss 7.860118\n",
            "Epoch 1000, Loss 3.828538\n",
            "Epoch 1500, Loss 3.092191\n",
            "Epoch 2000, Loss 2.957697\n",
            "Epoch 2500, Loss 2.933134\n",
            "Epoch 3000, Loss 2.928648\n",
            "Epoch 3500, Loss 2.927830\n",
            "Epoch 4000, Loss 2.927680\n",
            "Epoch 4500, Loss 2.927651\n",
            "Epoch 5000, Loss 2.927648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWOu_8yuvRJa",
        "colab_type": "text"
      },
      "source": [
        "Instantiating a different optimizer, such as Adam, instead of SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORZ1YnhVvGOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "db370da9-5527-445a-c9c0-3a8efa3ea828"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-1\n",
        "optimizer = optim.Adam([params], lr=learning_rate)\n",
        "training_loop(\n",
        " n_epochs = 2000,\n",
        " optimizer = optimizer,\n",
        " params = params,\n",
        " t_u = t_u,\n",
        " t_c = t_c)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 500, Loss 7.612903\n",
            "Epoch 1000, Loss 3.086700\n",
            "Epoch 1500, Loss 2.928578\n",
            "Epoch 2000, Loss 2.927646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0.5367, -17.3021], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W84HytQOvjZJ",
        "colab_type": "text"
      },
      "source": [
        "Shuffling the elements of a tensor amounts to finding a permutation of its indices using randperm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glR3xkLGvfP1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "891fc2a8-4ffc-4907-d248-d98345d849cb"
      },
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "train_indices, val_indices "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 3, 10,  0,  7,  4,  6,  9,  2,  5]), tensor([8, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKprRLImv9SF",
        "colab_type": "text"
      },
      "source": [
        "get index tensors that you can use to build training and validation sets starting\n",
        "from the data tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0aDExgTvqAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_t_u = t_u[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_c = t_c[val_indices]\n",
        "train_t_un = 0.1 * train_t_u\n",
        "val_t_un = 0.1 * val_t_u"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4zrtzKYwCDY",
        "colab_type": "text"
      },
      "source": [
        "Training loop doesnâ€™t change. Wanted to evaluate the validation loss at every\n",
        "epoch to have a chance to recognize whether it is overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFauyttZwL_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c,\n",
        "val_t_c):\n",
        " for epoch in range(1, n_epochs + 1):\n",
        "  train_t_p = model(train_t_u, *params)\n",
        "  train_loss = loss_fn(train_t_p, train_t_c)\n",
        "  val_t_p = model(val_t_u, *params)\n",
        "  val_loss = loss_fn(val_t_p, val_t_c)\n",
        "  optimizer.zero_grad()\n",
        "  train_loss.backward()\n",
        "  optimizer.step()\n",
        "  if epoch <= 3 or epoch % 500 == 0:\n",
        "   print('Epoch {}, Training loss {}, Validation loss {}'.format(\n",
        "   epoch, float(train_loss), float(val_loss)))\n",
        " return params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYHO8uykwSLX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3fd9acc7-dae4-4489-cdde-eb3e01d3f97e"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "training_loop(\n",
        " n_epochs = 3000,\n",
        " optimizer = optimizer,\n",
        " params = params,\n",
        " train_t_u = train_t_un,\n",
        " val_t_u = val_t_un,\n",
        " train_t_c = train_t_c,\n",
        " val_t_c = val_t_c)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Training loss 90.21489715576172, Validation loss 36.03684616088867\n",
            "Epoch 2, Training loss 41.471065521240234, Validation loss 11.09175968170166\n",
            "Epoch 3, Training loss 34.153743743896484, Validation loss 12.061867713928223\n",
            "Epoch 500, Training loss 6.606430530548096, Validation loss 7.840882301330566\n",
            "Epoch 1000, Training loss 3.0961873531341553, Validation loss 5.740539073944092\n",
            "Epoch 1500, Training loss 2.6341655254364014, Validation loss 5.080069065093994\n",
            "Epoch 2000, Training loss 2.5733556747436523, Validation loss 4.853822231292725\n",
            "Epoch 2500, Training loss 2.565351724624634, Validation loss 4.773495197296143\n",
            "Epoch 3000, Training loss 2.564297676086426, Validation loss 4.744585037231445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3099, -16.8489], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3sCOBgOwa5f",
        "colab_type": "text"
      },
      "source": [
        "Making sure that this context manager\n",
        "works by checking the value of the requires_grad attribute on the val_loss tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbiqCUgzwWT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c,\n",
        "val_t_c):\n",
        " for epoch in range(1, n_epochs + 1):\n",
        "  train_t_p = model(train_t_u, *params)\n",
        "  train_loss = loss_fn(train_t_p, train_t_c)\n",
        "  with torch.no_grad():\n",
        "   val_t_p = model(val_t_u, *params)\n",
        "   val_loss = loss_fn(val_t_p, val_t_c)\n",
        "   assert val_loss.requires_grad == False\n",
        "  optimizer.zero_grad()\n",
        "  train_loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha_L9iFPwwJZ",
        "colab_type": "text"
      },
      "source": [
        "Defining a calc_forward\n",
        "function that takes data in input and runs model and loss_fn with or without autograd, according to a Boolean train_is argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18fLUVEfwowH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_forward(t_u, t_c, is_train):\n",
        " with torch.set_grad_enabled(is_train):\n",
        "  t_p = model(t_u, *params)\n",
        "  loss = loss_fn(t_p, t_c)\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}