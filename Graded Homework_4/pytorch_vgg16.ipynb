{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_vgg16.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMA7zg7bmCH+TWK2gGrQgFV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monicasjsu/deep_learning/blob/master/pytorch_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuK11BBr8ScZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH2nqbhL8a1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cfg = {\n",
        "    'D' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256,      'M', 512, 512, 512,      'M', 512, 512, 512,      'M']\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, features, num_class=100):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.features(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.classifier(output)\n",
        "    \n",
        "        return output\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "\n",
        "    input_channel = 3\n",
        "    for l in cfg:\n",
        "        if l == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            continue\n",
        "\n",
        "        layers += [nn.Conv2d(input_channel, l, kernel_size=3, padding=1)]\n",
        "\n",
        "        if batch_norm:\n",
        "            layers += [nn.BatchNorm2d(l)]\n",
        "        \n",
        "        layers += [nn.ReLU(inplace=True)]\n",
        "        input_channel = l\n",
        "    \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def vgg16_bn():\n",
        "    return VGG(make_layers(cfg['D'], batch_norm=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAfyjtdf8eVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "e895937f-7b39-49d2-a3f6-d2d98e77e23a"
      },
      "source": [
        "vgg16 = vgg16_bn()\n",
        "print(vgg16)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnWLZQ1iGjSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8f21d400-d081-4ba1-e869-a49898d0ae8d"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        " \n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True)\n",
        " \n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ozx68nqIKVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change the number of classes \n",
        "vgg16.classifier[6].out_features = 100\n",
        " \n",
        "# freeze convolution weights\n",
        "for param in vgg16.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnv3ifVMFRs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer\n",
        "optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001, momentum=0.9)\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywQEL6f6Ez_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#validation function\n",
        "def validate(model, test_dataloader):\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_running_correct = 0\n",
        "    for int, data in enumerate(test_dataloader):\n",
        "        data, target = data[0].to(device), data[1].to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        val_running_loss += loss.item()\n",
        "        _, preds = torch.max(output.data, 1)\n",
        "        val_running_correct += (preds == target).sum().item()\n",
        "    \n",
        "    val_loss = val_running_loss/len(test_dataloader.dataset)\n",
        "    val_accuracy = 100. * val_running_correct/len(test_dataloader.dataset)\n",
        "    \n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypIy2It0E594",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training function\n",
        "def fit(model, train_dataloader):\n",
        "    model.train()\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        data, target = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        train_running_loss += loss.item()\n",
        "        _, preds = torch.max(output.data, 1)\n",
        "        train_running_correct += (preds == target).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    train_loss = train_running_loss/len(train_dataloader.dataset)\n",
        "    train_accuracy = 100. * train_running_correct/len(train_dataloader.dataset)\n",
        " \n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}')\n",
        "    \n",
        "    return train_loss, train_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8AYaeuVE-0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fb2a1c0a-5934-4129-a2e6-b23adc50b036"
      },
      "source": [
        "import time\n",
        "\n",
        "train_loss , train_accuracy = [], []\n",
        "val_loss , val_accuracy = [], []\n",
        "start = time.time()\n",
        "for epoch in range(10):\n",
        "    train_epoch_loss, train_epoch_accuracy = fit(vgg16, trainloader)\n",
        "    val_epoch_loss, val_epoch_accuracy = validate(vgg16, testloader)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    train_accuracy.append(train_epoch_accuracy)\n",
        "    val_loss.append(val_epoch_loss)\n",
        "    val_accuracy.append(val_epoch_accuracy)\n",
        "end = time.time()\n",
        " \n",
        "print((end-start)/60, 'minutes')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0358, Train Acc: 1.49\n",
            "Train Loss: 0.0352, Train Acc: 2.59\n",
            "Train Loss: 0.0347, Train Acc: 3.65\n",
            "Train Loss: 0.0343, Train Acc: 4.49\n",
            "Train Loss: 0.0339, Train Acc: 5.48\n",
            "Train Loss: 0.0334, Train Acc: 6.51\n",
            "Train Loss: 0.0329, Train Acc: 7.32\n",
            "Train Loss: 0.0325, Train Acc: 7.94\n",
            "Train Loss: 0.0321, Train Acc: 8.59\n",
            "Train Loss: 0.0317, Train Acc: 9.28\n",
            "90.83236281474431 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}